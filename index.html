<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepDive Podcast</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f9f9f9;
            color: #333;
            margin: 0;
            padding: 20px;
            display: flex;
            justify-content: center;
            gap: 20px;
            background-image: url('https://raw.githubusercontent.com/mossavatFontys/deepdivepod/cee119a959cabe2964621bd1f26778f29ffca0ba/assets/background.jpg');
            background-size: cover;
            background-position: center;
            height: 100vh;
        }
        .content {
            max-width: 800px;
            position: relative;
            z-index: 2;
            background-color: rgba(255, 255, 255, 0.8); /* Add a white background with opacity to ensure content visibility */
            padding: 20px;
            border-radius: 8px;
        }

        h1 {
            color: #000000;
            text-align: center;
            font-size: 3em;
            margin: 20px 0;
        }

        .subtitle {
            font-size: 1.1em;
            text-align: center;
            color: #000000;
        }

        .subsubtitle {
            font-size: 1em;
            text-align: center;
            color: #383737;  /* Lighter color for the subsub title */
        }

        .episode {
            background-color: #ffffff;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
            text-align: left;
        }
        .episode h2 {
            color: #2d2d7d;
        }
        iframe {
            width: 100%;
            height: 80px;
            border-radius: 8px;
        }
        .description {
            font-size: 1em;
            margin-top: 10px;
            color: #666;
            text-align: left;
        }
        a {
            color: #2d2d7d;
            text-decoration: none;
            font-weight: bold;
        }
        a:hover {
            text-decoration: underline;
        }

        .contact-btn {
            position: fixed;
            bottom: 20px;
            right: 20px;
            font-size: 0.9em;  /* Smaller font size */
            color: #666;  /* Milder color */
            font-weight: normal;  /* Remove bold */
            text-decoration: none;  /* No underline */
            background-color: rgba(255, 255, 255, 0.7);  /* Light background */
            padding: 10px;
            border-radius: 5px;
            z-index: 999; /* Ensure it stays above content */
        }

        @media screen and (max-width: 600px) {
            .contact-btn {
                bottom: 10px; /* Adjust the button position for small screens */
                right: 10px;
                font-size: 0.8em; /* Slightly smaller font */
                padding: 8px; /* Adjust padding */
            }
        }
                

        .contact-link:hover {
            color: #2d2d7d;  /* Darker color on hover */
            background-color: rgba(255, 255, 255, 0.9);
        }
        .radio-logo {
            display: block;
            margin: 20px auto;
            width: 200px;
            height: auto;
        }

    </style>
</head>
<body>

    <div class="content">
        <h1>DeepDive Podcast</h1>
        <p class="subtitle">Conversations on humans and machines</p>
        <p class="subsubtitle">In collaboration with <a href="https://www.radio4brainport.org/" target="_blank">Radio4Brainport</a></p>


        <!-- Episode 11 -->
        <div class="episode">
            <h2>Episode 11: Robert Engels: "Agents need the same thing as you and I: they need an idea of intent and purpose of the counterpart or adversary"</h2>
            <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/0HcECLegRufdTrwKSuuf7P?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

            <p class="description">Iman Mossavat engages Robert Engels, Head of AI Futures Lab at Capgemini, in a discussion on the role of context and abstraction in AI. With 36 years of experience, Engels examines why current generative AI systems, like GPT-4, excel at tasks yet fail in complex, real-world settings. Robert argues, \‚ÄúTwo things are underperforming in the world of generative AI‚Äîabstraction and logical reasoning.\‚Äù Robert underscores the need for AI to adopt a world model akin to philosophical reasoning: "Plato and Socrates understood this when they built logics‚Äîthey looked at the world and tried to grasp its principles." </p>
            <p><a href="https://www.linkedin.com/in/robertengels/" target="_blank">LinkedIn (Robert Engels)</a></p>
            <p>Tags: Context, Iman Mossavat, Eindhoven, Innovation, AI, Abstraction, GPT, Capgemini</p>
        </div>

        <!-- Episode 10 -->
        <div class="episode">
            <h2>Episode 10: Artin Entezarjou: "AI vs Doctors: Human Judgement Wins (for time being) in Complex Medical Contexts"</h2>

            <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/0TppO8PGrmA1h888TMJ5WK?utm_source=generator"
        width="100%" height="352" frameBorder="0" allowfullscreen=""
        allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

            <p class="description">Our host Iman Mossavat welcomes Dr. Artin Entezarjou, a board-certified general medicine specialist, to discuss AI's role in healthcare. Dr. Entezarjou highlights AI's progress and challenges in handling complex clinical scenarios. ‚ÄúHumans can outperform AI when questions aren‚Äôt multiple choice, especially when psychosocial factors are involved,‚Äù he explains. His research comparing GPT-4 to human doctors reveals AI's limitations in understanding real-world medical complexities and patient contexts. ‚ÄúClinical decisions require more than symptoms; they demand insight into patients‚Äô preferences and circumstances,‚Äù he says. Dr. Entezarjou stresses the continued need for human judgment, adding, ‚ÄúWe‚Äôre still the masters of recognizing when more context is needed, though this is rapidly changing.‚Äù He advocates for AI systems that are robust, trustworthy, and intuitive, emphasizing their role in supporting‚Äînot replacing‚Äîphysicians. ‚ÄúAI can excel in specific tasks, but general judgment remains human,‚Äù he concludes</p>
            <p><a href="https://bmjopen.bmj.com/content/14/12/e086148" target="_blank">Study</a></p><p><a href="https://www.linkedin.com/in/artin-entezarjou-330624137/" target="_blank">LinkedIn (Artin Entezarjou)</a></p>
            <p>Tags: Eindhoven, Healthcare, Innovation, Health, Clinical, Iman Mossavat, Care, AI, Medicine</p>
        </div>

        <!-- Episode 9 -->
        <div class="episode">
            <h2>Episode 9: Diederik Roijers: "What If We Optimized for Enough, Not More?"</h2>
            <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/7MdFF5ckblYIPDr4U33ocp?utm_source=generator&theme=0" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
            <p class="description">Join Iman Mossavat as he speaks with 
                <a href="https://roijers.info/" target="_blank">Diederik Roijers</a>, senior researcher at the AI Lab at Vrije Universiteit Brussel. Diederik specializes in <strong>Multi-Objective Reinforcement Learning (MORL)</strong>, a framework that shifts focus from optimizing a single outcome to balancing multiple, sometimes competing, objectives. 

                Drawing on the ancient idea of balance‚Äîakin to Yin and Yang‚ÄîDiederik challenges the status quo of ‚Äúmaximizing more.‚Äù Instead, he advocates for pursuing outcomes that are <strong>"good enough"</strong>, prioritizing practicality, ethics, and societal benefit over perfection. 
                
                üí° Key Insight: How can AI navigate trade-offs like maximizing rewards while minimizing risks? Diederik‚Äôs vision emphasizes deliberate choices in AI design, promoting transparency, maintainability, and alignment with societal values. Together, they explore how AI can serve everyone fairly‚Äînot just a select few‚Äîwhile balancing innovation and responsibility.

                Tune in for a refreshing perspective on building AI systems that prioritize balance, fairness, and shared benefit.
            </p>
            <p>For more about Diederik Roijers:  
                <a href="https://scholar.google.com/citations?user=oi25V4EAAAAJ" target="_blank">Google Scholar</a>
            </p>
        </div>
        <!-- Episode 8 -->
        <div class="episode">
            <h2>Episode 8: Weaving Trustworthy AI with Threads of Reason: The Subtle Genius of Professor Mehdi Dastani</h2>
            <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/2GCHWC3t8mcAMZ3ynxMMKV?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
            <p class="description">Join Iman Mossavat for an enlightening conversation with Professor 
                <a href="https://www.uu.nl/medewerkers/MMDastani" target="_blank">Mehdi Dastani</a>, Chair of the Intelligent Systems group at Utrecht University. With over 500 scientific contributions, Professor Dastani has spent decades merging computer science and philosophy in a way that challenges and inspires. 
                His work spans formal logic, reinforcement learning, ethics, and human-centered AI, bringing fresh perspectives to the challenges facing modern technology.
                
                Key Insight: Professor Dastani emphasizes the need for a fusion of machine learning, formal reasoning, and domain expertise to create AI systems that are safe, ethical, and aligned with human values. His interdisciplinary approach, drawing from psychology, law, and philosophy, offers innovative solutions to issues like AI bias, accountability, and safety risks. 
                <li><a href="https://scholar.google.nl/citations?user=rvG4n98AAAAJ" target="_blank">Mehdi Dastani on Google Scholar</a></li>               
            </p>
        </div>

        <!-- Episode 7 -->
        <div class="episode">
            <h2>Episode 7: Lazy But Brilliant: How LazyDynamics is Set to Redefine Real-Time Decision Making with Reactive AI</h2>
        <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/5IZWs2vukrUwejIrrF7PK4?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
        <p class="description">Join Iman Mossavat for an insightful episode with special guests 
            <a href="https://www.linkedin.com/in/albertpod/" target="_blank">Albert Podusenko</a> and 
            <a href="https://www.linkedin.com/in/ismail-senoz/" target="_blank">ƒ∞smail ≈ûen√∂z</a>, as we dive into the innovative world of 
            <a href="https://lazydynamics.com/" target="_blank">Lazy Dynamics</a>. This cutting-edge company is reshaping how agents process and act on real-time data in unpredictable environments. Their software streamlines the development of intelligent systems capable of navigating uncertainty ‚Äî whether it's an ambulance optimizing routes or legal tech helping lawyers model strategic uncertainties in complex litigation.
            
            At the heart of their approach is <a href="https://rxinfer.ml/" target="_blank">RxInfer</a>, a fast and efficient tool designed to overcome the computational limitations of traditional <strong>probabilistic programming</strong> libraries, enabling real-time decision-making. With a unique <strong> reactive message-passing</strong> system, Lazy Dynamics ensures agents can keep reasoning even if some sensors fail ‚Äî a true breakthrough for dynamic, high-stakes environments.
            
            Discover how collaboration and <strong> open-source </strong> contributions are fueling their success and how these innovations are shaping the future. Tune in for an episode packed with insights into the future of AI and real-time decision-making!
            
            For more about the guests:
            <ul>
                <li><a href="https://scholar.google.com/citations?user=JHnjtN4AAAAJ" target="_blank">Albert Podusenko on Google Scholar</a></li>
                <li><a href="https://scholar.google.nl/citations?hl=en&user=t2ZEDP0AAAAJ" target="_blank">ƒ∞smail ≈ûen√∂z on Google Scholar</a></li>
            </ul>
            </p>
        </div>

        <!-- Episode 6 -->
        <div class="episode">
            <h2>Episode 6: Is your AI project legally compliant, with Inge Brattinga</h2>
            <iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/1vFZ9ZidZL9vAkRTkLYEsH?utm_source=generator" width="100%" height="352" frameborder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
            <p class="description">In this episode, <a href="https://www.vrfadvocaten.nl/blog/team/inge-brattinga/" target="_blank">Inge Brattinga</a>, lawyer at VRF Advocaten and lecturer at Avans University, discusses how AI is reshaping hiring, human-resources (HR), decision-making, and privacy. She highlights the importance of AI literacy, offering practical advice for businesses navigating upcoming regulations.</p>
        </div>


        <!-- Episode 5 -->
        <div class="episode">
            <h2>Episode 5: Evolutionary Science and AI with Indre ≈Ωliobaitƒó</h2>
            <iframe src="https://open.spotify.com/embed/episode/2BzPwHFPBRxmUoMjAaIiYI?utm_source=generator" frameborder="0" allowfullscreen="" loading="lazy"></iframe>
            <p class="description">Professor <a href="https://www.zliobaite.com/" target="_blank">Indre ≈Ωliobaitƒó</a> explores parallels between evolutionary science and AI, discussing adaptive models, concept drift, and more. She explains how principles of evolution can inform AI, providing insights into dynamics like competition and adaptation.</p>
        </div>

        <!-- Episode 4 -->
        <div class="episode">
            <h2>Episode 4: Legal Challenges of AI with Colette Cuijpers</h2>
            <iframe src="https://open.spotify.com/embed/episode/1oe9HWEoT6XJvPTrrGNZk3?utm_source=generator" frameborder="0" allowfullscreen="" loading="lazy"></iframe>
            <p class="description"><a href="https://research.tilburguniversity.edu/en/persons/colette-cuijpers" target="_blank">Colette Cuijpers</a>, Associate Professor at Tilburg Law School, discusses the urgent legal and ethical challenges AI presents, from accountability to bias. This episode highlights the balance between innovation and regulation in a rapidly evolving field.</p>
        </div>

        <!-- Episode 3 -->
        <div class="episode">
            <h2>Episode 3: Causal AI and Intelligent Systems with Alexander Molak</h2>
            <iframe src="https://open.spotify.com/embed/episode/0xghHS4lo0aW22sI5VVH11?utm_source=generator" frameborder="0" allowfullscreen="" loading="lazy"></iframe>
            <p class="description"><a href="https://alxndr.io/" target="_blank">Alexander Molak</a>, machine learning researcher, explains why Generative AI lacks true causal understanding. He discusses Causal AI and its potential to improve intelligent systems by moving beyond mere correlation to deeper cause-and-effect insights.</p>
        </div>

        <!-- Episode 2 -->
        <div class="episode">
            <h2>Episode 2: Systems Engineering and AI with Gerrit Muller</h2>
            <iframe src="https://open.spotify.com/embed/episode/0C0GGgkFuwFlFmZvmqulm4?utm_source=generator" frameborder="0" allowfullscreen="" loading="lazy"></iframe>
            <p class="description">Gerrit Muller, a systems engineer and professor, discusses the integration of systems engineering and AI, exploring the importance of a balanced approach. He examines common challenges, such as data quality and interpretability, and the complementary role of Model-Based Systems Engineering.</p>
        </div>

        <!-- Episode 1 -->
        <div class="episode">
            <h2>Episode 1: Understanding Power Dynamics in AI with Mahault Albarracin</h2>
            <iframe src="https://open.spotify.com/embed/episode/3uHMBoorJXPnIZoYvdMrla?utm_source=generator" frameborder="0" allowfullscreen="" loading="lazy"></iframe>
            <p class="description">Mahault Albarracin, Director of Applied Research and PhD candidate in Computing, discusses how AI often prioritizes objectives set by powerful stakeholders, affecting societal power structures. This episode explores the intersection of technology, ethics, and power in AI design.</p>
        </div>

        <!-- Radio4Brainport Logo -->
        <img src="https://www.radio4brainport.org/site2019/wp-content/uploads/2019/07/Logo-Radio4Brainport-320x240.png" alt="Radio4Brainport Logo" class="radio-logo">

    </div>

    <a href="contact.html" class="contact-btn">Contact</a>

</body>
</html>
